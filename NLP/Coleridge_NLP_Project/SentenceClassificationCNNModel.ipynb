{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mention Classification Model:\n",
    "\n",
    "This model was trained to take all sentences talking about a named entity and classify them as dataset mentions or not. The training pipeline was as follows:\n",
    "\n",
    "- Load Training and filter to sentences between 5 and 65 length.\n",
    "- Preprocess the Sentences\n",
    "    - Expand Abbreviations\n",
    "    - Remove punctuations\n",
    "    - Remove non albhabetical words\n",
    "    - Make lower case\n",
    "    - Perform word stemming\n",
    "    - Special mapping (e.g replace study by survey)\n",
    "- Build a vocabulary\n",
    "- Tokenize sentences into vectors\n",
    "- Train the model\n",
    "\n",
    "### Classifer\n",
    "ANN classifier was used for this purpose. We were inspired by the wide use of CNNs are widely used for document classification but also realized that LSTMs are better at modeling intricate linguistic qualities specially the ones with long range dependencies. Hence we tested both LSTMs and CNN for this task and CNNs gave us better results (I would like to state that our testing of these paradigms was not exhaustive in terms of achitecture and hyperparameters). We observed that our model tended to overfit very quickly so we had to limit training to a very few epochs and introduce strict dropout, becuase we wanted our model to generalize rather than learn the input data. We were able to achive good accuracy on our dataset after hyperparameter tuning and trying different data cleaning methods. Following are important observations:\n",
    "- abbreviation expansion module aimproved accuracy by 7 %\n",
    "- word stemming improved accuracy by 6 %\n",
    "- word2vec or GloVe word embeddings did not do well\n",
    "- training our own embedding layer with the model did well\n",
    "\n",
    "### Model Architecture:\n",
    "After hyperparamter tuning the following architecture was selected:\n",
    "<img src=\"modelArchi.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from os import listdir\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save a list as a text file\n",
    "def save_list(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    " \n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load positive sentences\n",
    "positiveSentences = load_doc('all_positive_sentences.txt').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load negative senteces\n",
    "negativeSentences = load_doc('all_negative_sentences.txt').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter sentences by length\n",
    "positiveSentences = [s for s in positiveSentences if len(s.split()) > 5 and len(s.split()) < 65]\n",
    "negativeSentences = [s for s in negativeSentences if len(s.split()) > 5 and len(s.split()) < 65] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33625"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Randomly select negative examples to ballance class sizes\n",
    "from sklearn.model_selection import train_test_split\n",
    "ratio = len(positiveSentences)/len(negativeSentences)\n",
    "_, negativeSentences, _, _ = train_test_split(negativeSentences, np.ones(len(negativeSentences)), test_size=ratio)\n",
    "len(negativeSentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load abbreviations\n",
    "file = 'abbreviations.json'\n",
    "abbtext = load_doc(file)\n",
    "abbreviations = json.loads(abbtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAbbreviation(sentence):\n",
    "    regex = r\"\\b[A-Z][A-Z]+\\b\"\n",
    "    abbreviations = re.findall(regex, sentence)\n",
    "    return abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expandAbbreviation(sentence, abbdict):\n",
    "    abbs = findAbbreviation(sentence)\n",
    "    for a in abbs:\n",
    "        if a in abbdict:\n",
    "            sentence = sentence.replace(a,abbdict[a][0])\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def specialMapping(word):\n",
    "    if word == 'studi':\n",
    "        return 'survey'\n",
    "    else:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "    # abbreviation disambiguation\n",
    "    doc = expandAbbreviation(doc, abbreviations)\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    # remove punctuation from each token\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # make lower case\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # stemming\n",
    "    tokens = [ps.stem(word) for word in tokens]\n",
    "    #specialMapping\n",
    "    tokens = [specialMapping(word) for word in tokens]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc and add to vocab\n",
    "def add_doc_to_vocab(sentence, vocab):\n",
    "\t# clean doc\n",
    "\ttokens = clean_doc(sentence)\n",
    "\t# update counts\n",
    "\tvocab.update(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_docs(sentences, vocab):\n",
    "    # walk through all files in the folder\n",
    "    for sentence in sentences:\n",
    "        add_doc_to_vocab(sentence, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41776\n",
      "[('survey', 43501), ('health', 32462), ('nation', 31143), ('examin', 20376), ('nutrit', 18962), ('data', 11460), ('use', 11258), ('age', 7899), ('sampl', 6195), ('iii', 5258)]\n"
     ]
    }
   ],
   "source": [
    "# define vocab\n",
    "vocab1 = Counter()\n",
    "# add all docs to vocab\n",
    "process_docs(positiveSentences, vocab1)\n",
    "process_docs(negativeSentences, vocab1)\n",
    "# print the size of the vocab\n",
    "print(len(vocab1))\n",
    "# print the top words in the vocab\n",
    "print(vocab1.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2233\n"
     ]
    }
   ],
   "source": [
    "# keep tokens with > 5 occurrence\n",
    "min_occurane = 50\n",
    "tokens = [k for k,c in vocab1.items() if c >= min_occurane]\n",
    "print(len(tokens))\n",
    "# save tokens to a vocabulary file\n",
    "save_list(tokens, 'bmvocab.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Prepared Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc, clean and return line of tokens\n",
    "def doc_to_line(sentence, vocab):\n",
    "\t# clean doc\n",
    "\ttokens = clean_doc(sentence)\n",
    "\t# filter by vocab\n",
    "\ttokens = [w for w in tokens if w in vocab]\n",
    "\treturn ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all docs in a directory\n",
    "def process_docs(sentences, vocab):\n",
    "    lines = list()\n",
    "    # walk through all files in the folder\n",
    "    for sentence in sentences:\n",
    "        # load and clean the doc\n",
    "        line = doc_to_line(sentence, vocab)\n",
    "        # add to list\n",
    "        lines.append(line)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vocabulary\n",
    "vocab_filename = 'bmvocab.txt'\n",
    "vocab = load_doc(vocab_filename)\n",
    "vocab = vocab.split()\n",
    "vocab = set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare negative reviews\n",
    "negative_lines = process_docs(negativeSentences, vocab)\n",
    "save_list(negative_lines, 'negative.txt')\n",
    "# prepare positive reviews\n",
    "positive_lines = process_docs(positiveSentences, vocab)\n",
    "save_list(positive_lines, 'positive.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from os import listdir\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all training reviews\n",
    "positive_docs = load_doc('positive.txt').split('\\n')\n",
    "negative_docs = load_doc('negative.txt').split('\\n')\n",
    "x = negative_docs + positive_docs\n",
    "y = array([0 for _ in range(len(negative_docs))] + [1 for _ in range(len(positive_docs))])\n",
    "#train_docs = negative_docs + positive_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "# fit the tokenizer on the documents\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence encode\n",
    "encoded_docs = tokenizer.texts_to_sequences(X_train)\n",
    "# pad sequences\n",
    "max_length = max([len(s.split()) for s in X_train])\n",
    "Xtrain = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence encode\n",
    "encoded_docs = tokenizer.texts_to_sequences(X_test)\n",
    "# pad sequences\n",
    "Xtest = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vocabulary size (largest integer value)\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 66, 100)           223400    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 63, 16)            6416      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 31, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 496)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 496)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                4970      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 234,797\n",
      "Trainable params: 234,797\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
    "# model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(10, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# print(model.summary())\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_length))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=16, kernel_size=4, activation='relu'))\n",
    "# f 8 k 16\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile network\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " - 8s - loss: 0.3034 - acc: 0.8972\n",
      "Epoch 2/3\n",
      " - 8s - loss: 0.2136 - acc: 0.9399\n",
      "Epoch 3/3\n",
      " - 7s - loss: 0.1887 - acc: 0.9458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd224321ef0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit network\n",
    "model.fit(Xtrain, y_train, epochs=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 94.944238\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "loss, acc = model.evaluate(Xtest, y_test, verbose=0)\n",
    "print('Test Accuracy: %f' % (acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision RecallAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Acc   F_score      Prec       Rec         t\n",
      "0   0.504238  0.670423  0.504238  1.000000  0.000000\n",
      "1   0.795688  0.830726  0.713394  0.994249  0.034483\n",
      "2   0.885279  0.897003  0.819490  0.990711  0.068966\n",
      "3   0.913457  0.919857  0.862826  0.984960  0.103448\n",
      "4   0.925204  0.929729  0.883329  0.981274  0.137931\n",
      "5   0.930706  0.934394  0.893992  0.978620  0.172414\n",
      "6   0.934944  0.938053  0.902220  0.976850  0.206897\n",
      "7   0.937993  0.940708  0.908292  0.975523  0.241379\n",
      "8   0.940446  0.942888  0.912881  0.974934  0.275862\n",
      "9   0.941933  0.944186  0.916100  0.974049  0.310345\n",
      "10  0.943197  0.945249  0.919548  0.972427  0.344828\n",
      "11  0.945056  0.946907  0.923357  0.971690  0.379310\n",
      "12  0.946989  0.948635  0.927455  0.970805  0.413793\n",
      "13  0.948104  0.949588  0.930634  0.969331  0.448276\n",
      "14  0.949888  0.951181  0.934795  0.968151  0.482759\n",
      "15  0.951004  0.952125  0.938422  0.966234  0.517241\n",
      "16  0.953234  0.954104  0.944388  0.964022  0.551724\n",
      "17  0.954498  0.955198  0.948532  0.961958  0.586207\n",
      "18  0.955019  0.955525  0.952793  0.958272  0.620690\n",
      "19  0.955167  0.955462  0.957230  0.953701  0.655172\n",
      "20  0.954721  0.954792  0.961429  0.948245  0.689655\n",
      "21  0.952937  0.952779  0.964216  0.941610  0.724138\n",
      "22  0.949517  0.949028  0.966662  0.932026  0.758621\n",
      "23  0.946022  0.945133  0.969457  0.921999  0.793103\n",
      "24  0.940743  0.939193  0.973123  0.907549  0.827586\n",
      "25  0.934126  0.931646  0.977023  0.890298  0.862069\n",
      "26  0.923866  0.919962  0.978876  0.867738  0.896552\n",
      "27  0.906022  0.898783  0.983526  0.827485  0.931034\n",
      "28  0.865130  0.847460  0.986106  0.742996  0.965517\n",
      "29  0.495762       NaN       NaN  0.000000  1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/urwa/miniconda3/envs/nlp/lib/python3.6/site-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "y_prob = model.predict(Xtest).reshape(len(y_test),)\n",
    "\n",
    "result = []\n",
    "for t in np.linspace(0,1,30):\n",
    "    acc = sum( (y_prob>t) == y_test)/len(y_prob == y_test)\n",
    "    prec = sum( ((y_prob>t) == y_test) & (y_prob>t) )/sum(y_prob>t)\n",
    "    rec = sum( ((y_prob>t) == y_test) & (y_prob>t) )/sum(y_test)\n",
    "    fscore = 2*(prec * rec)/(prec + rec)\n",
    "    result .append({'t':t, 'Acc':acc , 'Prec':prec, 'Rec':rec, 'F_score': fscore})\n",
    "print(pd.DataFrame(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving model and tokenizer for reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"CNNmodel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"CNNmodel.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('CNNtokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20175"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
